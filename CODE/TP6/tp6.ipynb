{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distances(X):\n",
    "    \"\"\"\n",
    "    Computes the pairwise Euclidean distances between all points in X.\n",
    "    \n",
    "    Args:\n",
    "        X (np.array): The input data of shape (n_samples, n_features).\n",
    "        \n",
    "    Returns:\n",
    "        distances (np.array): Pairwise distance matrix of shape (n_samples, n_samples).\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    distances = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i + 1, n_samples):\n",
    "            distances[i, j] = np.linalg.norm(X[i] - X[j])\n",
    "            distances[j, i] = distances[i, j]  # Symmetric matrix\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_neighbors_by_distances(distances, k):\n",
    "    \"\"\"\n",
    "    Finds the indices of the k-nearest neighbors for each point.\n",
    "    \n",
    "    Args:\n",
    "        distances (np.array): Pairwise distance matrix of shape (n_samples, n_samples).\n",
    "        k (int): Number of neighbors.\n",
    "    \n",
    "    Returns:\n",
    "        neighbors (np.array): Indices of the k-nearest neighbors for each point.\n",
    "    \"\"\"\n",
    "    neighbors = np.argsort(distances, axis=1)[:, 1:k+1]  # Exclude self\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(data, neighbors_indices, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Computes the reconstruction weights for each point.\n",
    "    \n",
    "    Args:\n",
    "        data (np.array): The input data of shape (n_samples, n_features).\n",
    "        neighbors_indices (np.array): Indices of the k-nearest neighbors.\n",
    "        alpha (float): Regularization term to avoid singularity.\n",
    "    \n",
    "    Returns:\n",
    "        W (np.array): Weight matrix of shape (n_samples, k).\n",
    "    \"\"\"\n",
    "    n_samples, n_features = data.shape\n",
    "    k = neighbors_indices.shape[1]\n",
    "    W = np.zeros((n_samples, k))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        neighbors = data[neighbors_indices[i]]\n",
    "        Z = neighbors - data[i]  # Center the neighbors to the point\n",
    "        C = Z @ Z.T  # Local covariance matrix\n",
    "        C += alpha * np.eye(k)  # Regularization to avoid singularity\n",
    "        \n",
    "        w = np.linalg.solve(C, np.ones(k))  # Solve for weights\n",
    "        W[i] = w / np.sum(w)  # Normalize weights to sum to 1\n",
    "    \n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lle(x, q, k=None, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Performs Locally Linear Embedding (LLE).\n",
    "    \n",
    "    Args:\n",
    "        x (np.array): The input data of shape (n_samples, n_features).\n",
    "        q (int): The target dimensionality for the embedding.\n",
    "        k (int, optional): The number of nearest neighbors (if not provided, defaults to n_features + 1).\n",
    "        alpha (float, optional): Regularization term (default 0.01).\n",
    "    \n",
    "    Returns:\n",
    "        Y (np.array): The embedding of shape (n_samples, q).\n",
    "    \"\"\"\n",
    "    n_samples, n_features = x.shape\n",
    "    \n",
    "    # If k is not provided, set k = n_features + 1\n",
    "    if k is None:\n",
    "        k = n_features + 1\n",
    "    \n",
    "    # Step 1: Compute pairwise distances\n",
    "    distances = euclidean_distances(x)\n",
    "    \n",
    "    # Step 2: Find k-nearest neighbors\n",
    "    neighbors_indices = find_k_neighbors_by_distances(distances, k)\n",
    "    \n",
    "    # Step 3: Compute the reconstruction weights\n",
    "    W = compute_weights(x, neighbors_indices, alpha)\n",
    "    \n",
    "    # Step 4: Compute the embedding by constructing the matrix M\n",
    "    M = np.zeros((n_samples, n_samples))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        for j in range(k):\n",
    "            M[i, neighbors_indices[i, j]] -= W[i, j]\n",
    "            M[neighbors_indices[i, j], i] -= W[i, j]\n",
    "        M[i, i] += 1\n",
    "    \n",
    "    # Step 5: Solve the eigenvalue problem\n",
    "    eigvals, eigvecs = np.linalg.eigh(M)\n",
    "    \n",
    "    # Step 6: Return the eigenvectors corresponding to the smallest q+1 eigenvalues (excluding the first one)\n",
    "    return eigvecs[:, 1:q+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume we have some data (n_samples, n_features)\n",
    "x = np.random.rand(100, 3)  # 100 samples, 3 features\n",
    "\n",
    "# Apply LLE to reduce the data to 2 dimensions\n",
    "embedding = lle(x, q=2, k=10, alpha=0.01)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
